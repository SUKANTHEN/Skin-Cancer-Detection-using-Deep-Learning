{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1) Importing Necessary Packages & Libraries"},{"metadata":{"id":"YfIk2es3hJEd","trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom tensorflow.keras import layers\nimport time\nimport cv2\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom IPython import display\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam,SGD","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining a function to automaticaly resize, reshape and normalize the use-case images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Dataset_loader(DIR,RESIZE):\n    IMG = []\n    read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\n    for IMAGE_NAME in tqdm(os.listdir(DIR)):\n        PATH = os.path.join(DIR,IMAGE_NAME)\n        _, ftype = os.path.splitext(PATH)\n        if ftype == \".jpg\":\n            img = read(PATH)\n            img = cv2.resize(img, (RESIZE,RESIZE))\n            IMG.append(np.array(img)/255.)\n    return IMG","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read and Import the dataset in 32 * 32 dimensions"},{"metadata":{"trusted":true},"cell_type":"code","source":"benign_train = np.array(Dataset_loader('../input/skin-cancer-malignant-vs-benign/train/benign',32))\nmalignant_train = np.array(Dataset_loader('../input/skin-cancer-malignant-vs-benign/train/malignant',32))\nbenign_test = np.array(Dataset_loader('../input/skin-cancer-malignant-vs-benign/test/benign',32))\nmalignant_test = np.array(Dataset_loader('../input/skin-cancer-malignant-vs-benign/test/malignant',32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"benign_train_label = np.zeros(len(benign_train))\nmalig_train_label = np.ones(len(malignant_train))\nbenign_test_label = np.zeros(len(benign_test))\nmalig_test_label = np.ones(len(malignant_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.concatenate((benign_train, malignant_train), axis = 0)\nY_train = np.concatenate((benign_train_label, malig_train_label), axis = 0)\nX_test = np.concatenate((benign_test, malignant_test), axis = 0)\nY_test = np.concatenate((benign_test_label, malig_test_label), axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = np.arange(X_train.shape[0])\nnp.random.shuffle(s)\nX_train = X_train[s]\nY_train = Y_train[s]\ns = np.arange(X_test.shape[0])\nnp.random.shuffle(s)\nX_test = X_test[s]\nY_test = Y_test[s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"S4PIDhoDLbsZ","trusted":true},"cell_type":"code","source":"img_rows = 32\nimg_cols = 32\nchannels = 3\n        \nimg_shape = (img_rows, img_cols, channels)        \nlatent_dim = 2637","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a Generator Model to generate images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator():\n\n        model = Sequential()\n\n        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=latent_dim))\n        model.add(Reshape((8, 8, 128)))\n        \n        model.add(UpSampling2D())#upsamples to 16*16*128\n        \n        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        \n        model.add(UpSampling2D()) #upsamples to 32*32*128\n        \n        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n        model.add(Activation(\"tanh\"))\n\n        #outputs an image of 32*32*3\n\n        noise = Input(shape=(latent_dim,))\n        img = model(noise)\n\n        return Model(noise, img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a Discriminator model to verify and check images generated by Generator model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator():\n\n        model = Sequential()\n\n        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        #no normalization for the first layer \n        \n        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        \n        model.add(Flatten())\n        model.add(Dense(1, activation='sigmoid'))\n        \n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n            optimizer=Adam(0.0002,0.5),\n            metrics=['accuracy'])\n\n# Build the generator\ngenerator = build_generator()\n\n# The generator takes noise as input and generates imgs\nz = Input(shape=(latent_dim,))\nimg = generator(z)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# The discriminator takes generated images as input and determines validity\nvalid = discriminator(img)\n\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002,0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_imgs(epoch):\n        r, c = 4,4\n        noise = np.random.normal(0, 1, (r * c,latent_dim))\n        gen_imgs = generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,])\n                axs[i,j].axis('off')\n                cnt += 1\n        plt.show()\n        plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_losses(losses):\n    losses = np.array(losses)\n    \n    fig, ax = plt.subplots()\n    plt.plot(losses.T[0], label='Discriminator')\n    plt.plot(losses.T[1], label='Generator')\n    plt.title(\"Training Losses\")\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=30000\nbatch_size=32\ndisplay_interval=5000\nlosses=[]  # Call an empty list \n        \n\n# Adversarial ground truths\nvalid = np.ones((batch_size, 1))\n        #let's add some noise \nvalid += 0.05 * np.random.random(valid.shape)\nfake = np.zeros((batch_size, 1))\nfake += 0.05 * np.random.random(fake.shape)\n\nfor epoch in range(epochs):\n    \n    idx = np.random.randint(0, X_train.shape[0], batch_size)\n    imgs = X_train[idx]\n\n            # Sample noise and generate a batch of new images\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    gen_imgs = generator.predict(noise)\n            \n\n            # Train the discriminator (real classified as ones and generated as zeros)\n    d_loss_real = discriminator.train_on_batch(imgs, valid)\n    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            \n            #  Train Generator\n            \n\n            # Train the generator (wants discriminator to mistake images as real)\n    g_loss = combined.train_on_batch(noise, valid)\n            \n            # Plot the progress\n    if epoch % 5000==0:\n        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n        if epoch % 1000==0:\n            losses.append((d_loss[0],g_loss))\n                \n            if epoch % display_interval == 0:\n                show_imgs(epoch)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_losses(losses)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generator generated images "},{"metadata":{"trusted":true},"cell_type":"code","source":"s=X_train[:40]\ns = 0.5 * s + 0.5\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(s):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SAMPLE Images produced by the Generator model after training for 30000 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = np.random.normal(size=(40, latent_dim))\ngenerated_images = generator.predict(noise)\ngenerated_images = 0.5 * generated_images + 0.5\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(generated_images):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}